{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd545cff",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Lab: Normalizing a Messy Dataset\n",
    "\n",
    "## 1. Prerequisites & Setup\n",
    "*   **Context:** This lab applies the normalization theory from Lesson 5.\n",
    "*   **Goal:** Take a denormalized \"flat\" table and progressively normalize it to 3NF.\n",
    "*   **Concept Review:** Ensure you have read `w03_l05_concept_normalization.md`.\n",
    "\n",
    "### Environment Setup\n",
    "Run this block first to set up the environment and load our messy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a47823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Run this cell first (required for Colab)\n",
    "# NOTE: Run cells in order. If you need to restart, re-run this cell first.\n",
    "!pip install -q pandas mermaid-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a527689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mermaid import Mermaid\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(\"Setup complete! Ready for normalization exercises.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c615d9f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "---\n",
    "\n",
    "## 2. The Scenario: A Messy Orders Table\n",
    "You've inherited a database from a small e-commerce company. They've been storing everything in one big \"flat\" table. Your job: normalize it.\n",
    "\n",
    "### The Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f0deb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our messy \"orders\" table\n",
    "messy_data = {\n",
    "    'order_id': [1001, 1001, 1002, 1002, 1002, 1003],\n",
    "    'order_date': ['2024-01-15', '2024-01-15', '2024-01-16', '2024-01-16', '2024-01-16', '2024-01-17'],\n",
    "    'customer_id': [501, 501, 502, 502, 502, 501],\n",
    "    'customer_name': ['Alice Smith', 'Alice Smith', 'Bob Jones', 'Bob Jones', 'Bob Jones', 'Alice Smith'],\n",
    "    'customer_email': ['alice@email.com', 'alice@email.com', 'bob@email.com', 'bob@email.com', 'bob@email.com', 'alice@email.com'],\n",
    "    'customer_city': ['New York', 'New York', 'Los Angeles', 'Los Angeles', 'Los Angeles', 'New York'],\n",
    "    'product_id': ['P001', 'P002', 'P001', 'P003', 'P004', 'P002'],\n",
    "    'product_name': ['Widget A', 'Widget B', 'Widget A', 'Gadget X', 'Gadget Y', 'Widget B'],\n",
    "    'product_category': ['Widgets', 'Widgets', 'Widgets', 'Gadgets', 'Gadgets', 'Widgets'],\n",
    "    'unit_price': [10.00, 15.00, 10.00, 25.00, 30.00, 15.00],\n",
    "    'quantity': [2, 1, 3, 1, 2, 4],\n",
    "}\n",
    "\n",
    "df_messy = pd.DataFrame(messy_data)\n",
    "df_messy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e83170",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected Output</summary>\n",
    "\n",
    "~~~text\n",
    "   order_id  order_date  customer_id customer_name   customer_email  customer_city product_id product_name product_category  unit_price  quantity\n",
    "0      1001  2024-01-15          501   Alice Smith  alice@email.com       New York       P001     Widget A          Widgets       10.00         2\n",
    "1      1001  2024-01-15          501   Alice Smith  alice@email.com       New York       P002     Widget B          Widgets       15.00         1\n",
    "2      1002  2024-01-16          502     Bob Jones    bob@email.com    Los Angeles       P001     Widget A          Widgets       10.00         3\n",
    "3      1002  2024-01-16          502     Bob Jones    bob@email.com    Los Angeles       P003     Gadget X          Gadgets       25.00         1\n",
    "4      1002  2024-01-16          502     Bob Jones    bob@email.com    Los Angeles       P004     Gadget Y          Gadgets       30.00         2\n",
    "5      1003  2024-01-17          501   Alice Smith  alice@email.com       New York       P002     Widget B          Widgets       15.00         4\n",
    "~~~\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Step 1: Identify the Problems\n",
    "\n",
    "Before normalizing, let's identify the anomalies.\n",
    "\n",
    "### Discussion Questions\n",
    "Look at the data and answer:\n",
    "\n",
    "1.  **Update Anomaly:** If Alice changes her email, how many rows need updating?\n",
    "2.  **Delete Anomaly:** If we delete order 1002, what customer information do we lose?\n",
    "3.  **Insert Anomaly:** Can we add a new product \"Gadget Z\" without an order?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a46a215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many times each customer appears\n",
    "print(\"Customer repetition (update anomaly risk):\")\n",
    "print(df_messy.groupby('customer_id')['customer_name'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5437400c",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected Output</summary>\n",
    "\n",
    "~~~text\n",
    "Customer repetition (update anomaly risk):\n",
    "customer_id\n",
    "501    3\n",
    "502    3\n",
    "Name: customer_name, dtype: int64\n",
    "~~~\n",
    "\n",
    "Alice's data is repeated 3 times, Bob's data is repeated 3 times. Any update to their info requires changing multiple rows!\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Step 2: Check 1NF (Atomicity)\n",
    "\n",
    "### Is our table in 1NF?\n",
    "\n",
    "**1NF Checklist:**\n",
    "- [x] All columns have atomic values (no lists or arrays)\n",
    "- [x] No repeating groups (no `product1`, `product2`, `product3` columns)\n",
    "- [x] Rows are distinguishable (though PK isn't clean)\n",
    "\n",
    "**Verdict:** This table IS in 1NF. Each cell contains a single value.\n",
    "\n",
    "> **What would a 1NF violation look like?** Imagine if we had stored products as a comma-separated list: `products: \"P001,P002\"`. That would violate 1NF because the cell isn't atomic. Our table avoids this by having separate rows per product.\n",
    "\n",
    "*But wait — what's the Primary Key?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7512f8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can order_id be the PK?\n",
    "print(\"Is order_id unique?\")\n",
    "print(df_messy['order_id'].is_unique)\n",
    "\n",
    "# What about (order_id, product_id)?\n",
    "print(\"\\nIs (order_id, product_id) unique?\")\n",
    "print(df_messy.groupby(['order_id', 'product_id']).size().max() == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46e33c1",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected Output</summary>\n",
    "\n",
    "~~~text\n",
    "Is order_id unique?\n",
    "False\n",
    "\n",
    "Is (order_id, product_id) unique?\n",
    "True\n",
    "~~~\n",
    "\n",
    "The Primary Key must be the **composite key**: `(order_id, product_id)`.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Step 3: Apply 2NF (Remove Partial Dependencies)\n",
    "\n",
    "### Identify Partial Dependencies\n",
    "With PK = `(order_id, product_id)`, let's check each attribute. Remember: a **partial dependency** means an attribute depends on only *part* of a composite key.\n",
    "\n",
    "| Attribute | Depends On | Dependency Type |\n",
    "| :--- | :--- | :--- |\n",
    "| `order_date` | `order_id` only | **Partial** ❌ (2NF violation) |\n",
    "| `customer_id` | `order_id` only | **Partial** ❌ (2NF violation) |\n",
    "| `product_name` | `product_id` only | **Partial** ❌ (2NF violation) |\n",
    "| `product_category` | `product_id` only | **Partial** ❌ (2NF violation) |\n",
    "| `unit_price` | `product_id` only | **Partial** ❌ (2NF violation) |\n",
    "| `quantity` | `(order_id, product_id)` | **Full** ✓ |\n",
    "\n",
    "> **What about `customer_name`, `customer_email`, `customer_city`?** These depend on `customer_id`, which itself depends on `order_id`. This is actually a **transitive dependency** (A → B → C), which we'll formally address when checking 3NF. For now, we'll extract them along with the customer_id they depend on.\n",
    "\n",
    "### Solution: Decompose into Three Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b04f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 1: orders (facts about the ORDER itself)\n",
    "df_orders = df_messy[['order_id', 'order_date', 'customer_id']].drop_duplicates()\n",
    "print(\"ORDERS table:\")\n",
    "print(df_orders)\n",
    "print()\n",
    "\n",
    "# Table 2: products (facts about the PRODUCT itself)\n",
    "df_products = df_messy[['product_id', 'product_name', 'product_category', 'unit_price']].drop_duplicates()\n",
    "print(\"PRODUCTS table:\")\n",
    "print(df_products)\n",
    "print()\n",
    "\n",
    "# Table 3: order_items (the relationship with quantity)\n",
    "df_order_items = df_messy[['order_id', 'product_id', 'quantity']]\n",
    "print(\"ORDER_ITEMS table:\")\n",
    "print(df_order_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54651284",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected Output</summary>\n",
    "\n",
    "~~~text\n",
    "ORDERS table:\n",
    "   order_id  order_date  customer_id\n",
    "0      1001  2024-01-15          501\n",
    "2      1002  2024-01-16          502\n",
    "5      1003  2024-01-17          501\n",
    "\n",
    "PRODUCTS table:\n",
    "  product_id product_name product_category  unit_price\n",
    "0       P001     Widget A          Widgets       10.00\n",
    "1       P002     Widget B          Widgets       15.00\n",
    "3       P003     Gadget X          Gadgets       25.00\n",
    "4       P004     Gadget Y          Gadgets       30.00\n",
    "\n",
    "ORDER_ITEMS table:\n",
    "   order_id product_id  quantity\n",
    "0      1001       P001         2\n",
    "1      1001       P002         1\n",
    "2      1002       P001         3\n",
    "3      1002       P003         1\n",
    "4      1002       P004         2\n",
    "5      1003       P002         4\n",
    "~~~\n",
    "\n",
    "</details>\n",
    "\n",
    "### But wait — where are the customers?\n",
    "In the original table, `customer_name`, `customer_email`, and `customer_city` all depend on `customer_id` — not on `order_id` directly. This is a **transitive dependency**:\n",
    "\n",
    "```\n",
    "order_id → customer_id → customer_name, customer_email, customer_city\n",
    "```\n",
    "\n",
    "While technically a 3NF issue, it's practical to extract these now. The customer attributes form their own logical entity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa56f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract customer data\n",
    "df_customers = df_messy[['customer_id', 'customer_name', 'customer_email', 'customer_city']].drop_duplicates()\n",
    "print(\"CUSTOMERS table:\")\n",
    "print(df_customers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daaea22",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected Output</summary>\n",
    "\n",
    "~~~text\n",
    "CUSTOMERS table:\n",
    "   customer_id customer_name   customer_email customer_city\n",
    "0          501   Alice Smith  alice@email.com      New York\n",
    "2          502     Bob Jones    bob@email.com   Los Angeles\n",
    "~~~\n",
    "\n",
    "Now each customer is stored exactly once.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Step 4: Apply 3NF (Remove Transitive Dependencies)\n",
    "\n",
    "We already extracted the customer attributes (a transitive dependency) in the previous step. Now let's verify all our tables are in 3NF.\n",
    "\n",
    "### Check the Orders Table\n",
    "Our current `orders` table:\n",
    "\n",
    "| order_id (PK) | order_date | customer_id |\n",
    "| :--- | :--- | :--- |\n",
    "\n",
    "**Dependencies:**\n",
    "*   `order_id → order_date` ✓ (Direct)\n",
    "*   `order_id → customer_id` ✓ (Direct)\n",
    "\n",
    "No transitive dependencies. **Orders is in 3NF!** ✓\n",
    "\n",
    "### Check the Products Table\n",
    "Our current `products` table:\n",
    "\n",
    "| product_id (PK) | product_name | product_category | unit_price |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "\n",
    "**Dependencies:**\n",
    "*   `product_id → product_name` ✓\n",
    "*   `product_id → product_category` ✓\n",
    "*   `product_id → unit_price` ✓\n",
    "\n",
    "No transitive dependencies. **Products is in 3NF!** ✓\n",
    "\n",
    "### Check the Customers Table\n",
    "Our current `customers` table:\n",
    "\n",
    "| customer_id (PK) | customer_name | customer_email | customer_city |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "\n",
    "**Dependencies:**\n",
    "*   `customer_id → customer_name` ✓\n",
    "*   `customer_id → customer_email` ✓\n",
    "*   `customer_id → customer_city` ✓\n",
    "\n",
    "No transitive dependencies. **Customers is in 3NF!** ✓\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Your Turn! (Exercises)\n",
    "\n",
    "### Exercise 1: Verify the Decomposition\n",
    "**Task:** Prove that we can reconstruct the original data by joining our normalized tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1740f5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Join df_orders, df_order_items, df_products, and df_customers\n",
    "# to recreate the original messy table\n",
    "\n",
    "# Hint: Start with order_items, then join orders, then products, then customers\n",
    "reconstructed = (\n",
    "    df_order_items\n",
    "    # .merge(df_orders, on='order_id')\n",
    "    # .merge(df_products, on='product_id')\n",
    "    # .merge(df_customers, on='customer_id')\n",
    ")\n",
    "\n",
    "# Uncomment and complete the joins above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09239c5f",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected Output</summary>\n",
    "\n",
    "~~~python\n",
    "reconstructed = (\n",
    "    df_order_items\n",
    "    .merge(df_orders, on='order_id')\n",
    "    .merge(df_products, on='product_id')\n",
    "    .merge(df_customers, on='customer_id')\n",
    ")\n",
    "print(reconstructed)\n",
    "~~~\n",
    "\n",
    "~~~text\n",
    "   order_id product_id  quantity  order_date  customer_id product_name product_category  unit_price customer_name   customer_email customer_city\n",
    "0      1001       P001         2  2024-01-15          501     Widget A          Widgets       10.00   Alice Smith  alice@email.com      New York\n",
    "1      1001       P002         1  2024-01-15          501     Widget B          Widgets       15.00   Alice Smith  alice@email.com      New York\n",
    "2      1002       P001         3  2024-01-16          502     Widget A          Widgets       10.00     Bob Jones    bob@email.com   Los Angeles\n",
    "3      1002       P003         1  2024-01-16          502     Gadget X          Gadgets       25.00     Bob Jones    bob@email.com   Los Angeles\n",
    "4      1002       P004         2  2024-01-16          502     Gadget Y          Gadgets       30.00     Bob Jones    bob@email.com   Los Angeles\n",
    "5      1003       P002         4  2024-01-17          501     Widget B          Widgets       15.00   Alice Smith  alice@email.com      New York\n",
    "~~~\n",
    "\n",
    "All original data is preserved through joins.\n",
    "\n",
    "</details>\n",
    "\n",
    "### Exercise 2: Find a Transitive Dependency\n",
    "**Task:** Consider this hypothetical `products` table with an additional column:\n",
    "\n",
    "| product_id | product_name | category_id | category_name |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| P001 | Widget A | C01 | Widgets |\n",
    "| P002 | Widget B | C01 | Widgets |\n",
    "| P003 | Gadget X | C02 | Gadgets |\n",
    "\n",
    "**Questions:**\n",
    "1.  Is this in 2NF? (The PK is `product_id` — single column)\n",
    "2.  Is this in 3NF? What's the transitive dependency?\n",
    "3.  How would you decompose it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed863748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create the decomposed tables as DataFrames\n",
    "# df_products_fixed = ...\n",
    "# df_categories = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e2bb72",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected Output</summary>\n",
    "\n",
    "**Answers:**\n",
    "1.  Yes, it's in 2NF (single-column PK means no partial dependencies possible).\n",
    "2.  No, it's NOT in 3NF. Transitive dependency: `product_id → category_id → category_name`\n",
    "3.  Decompose:\n",
    "\n",
    "~~~python\n",
    "df_products_fixed = pd.DataFrame({\n",
    "    'product_id': ['P001', 'P002', 'P003'],\n",
    "    'product_name': ['Widget A', 'Widget B', 'Gadget X'],\n",
    "    'category_id': ['C01', 'C01', 'C02']\n",
    "})\n",
    "\n",
    "df_categories = pd.DataFrame({\n",
    "    'category_id': ['C01', 'C02'],\n",
    "    'category_name': ['Widgets', 'Gadgets']\n",
    "})\n",
    "~~~\n",
    "\n",
    "</details>\n",
    "\n",
    "### Exercise 3: Anomaly Verification\n",
    "**Task:** Prove that our normalized design eliminates the anomalies we identified earlier.\n",
    "\n",
    "1.  **Update:** If Alice changes her email, how many rows need updating now?\n",
    "2.  **Delete:** If we delete order 1002, do we lose Bob's info?\n",
    "3.  **Insert:** Can we add product \"Gadget Z\" without an order?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda6b543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Answer each question with code that demonstrates the answer\n",
    "# For example, for Update:\n",
    "# print(f\"Rows to update for Alice's email: {len(df_customers[df_customers['customer_id'] == 501])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdeab34",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected Output</summary>\n",
    "\n",
    "~~~text\n",
    "1. Update: Only 1 row in the customers table needs updating.\n",
    "2. Delete: Bob's info stays in the customers table even if order 1002 is deleted.\n",
    "3. Insert: Yes! We can add to df_products without touching orders.\n",
    "~~~\n",
    "\n",
    "All three anomalies are eliminated.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Final Schema Diagram\n",
    "\n",
    "Here's our normalized schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fb9b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mermaid(\"\"\"\n",
    "erDiagram\n",
    "    customers {\n",
    "        int customer_id PK\n",
    "        varchar customer_name\n",
    "        varchar customer_email\n",
    "        varchar customer_city\n",
    "    }\n",
    "    orders {\n",
    "        int order_id PK\n",
    "        date order_date\n",
    "        int customer_id FK\n",
    "    }\n",
    "    products {\n",
    "        varchar product_id PK\n",
    "        varchar product_name\n",
    "        varchar product_category\n",
    "        decimal unit_price\n",
    "    }\n",
    "    order_items {\n",
    "        int order_id PK_FK\n",
    "        varchar product_id PK_FK\n",
    "        int quantity\n",
    "    }\n",
    "\n",
    "    customers ||--o{ orders : places\n",
    "    orders ||--|{ order_items : contains\n",
    "    products ||--o{ order_items : appears_in\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9798a3db",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Summary\n",
    "You have successfully:\n",
    "1.  Identified **anomalies** in a denormalized table.\n",
    "2.  Applied **1NF** (verified atomicity).\n",
    "3.  Applied **2NF** (removed partial dependencies from composite key).\n",
    "4.  Applied **3NF** (verified no transitive dependencies).\n",
    "5.  Decomposed one messy table into four normalized tables.\n",
    "\n",
    "**Key Insight:** Normalization trades **storage efficiency** and **data integrity** for **query complexity** (more joins). In the next lesson, we'll explore when it makes sense to intentionally denormalize.\n",
    "\n",
    "---\n",
    "\n",
    "**Ready for more?** Check the [Week 03 README](README.md) for an advanced challenge that applies these skills to a realistic retail dataset!"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
